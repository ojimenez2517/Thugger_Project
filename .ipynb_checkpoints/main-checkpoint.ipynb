{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66e4ca3f",
   "metadata": {},
   "source": [
    "# Young Thug Project - LIGN 6\n",
    "\n",
    "In this project my goal has been to compare the sound of Young Thug to other popular artists in the industry to see who compares to his unique style. My expectation is that other modern artists in the hip hop genre will be the most similar but I have also included more seasoned rappers as well as artists from pop and rock/alternative genres. \n",
    "\n",
    "I have featured 17 artists, I collected and cleaned 100 songs total; 20 songs from Young Thug and 5 for every other artist. The artists analyzed are:\n",
    "* Young Thug\n",
    "* Gunna\n",
    "* Lil Baby\n",
    "* J. Cole\n",
    "* Kendrick Lamar\n",
    "* Drake\n",
    "* Tyler, The Creator\n",
    "* Justin Bieber\n",
    "* Billie Ellish\n",
    "* Taylor Swift\n",
    "* Megan Thee Stallion\n",
    "* Adele\n",
    "* Olivia Rodrigo\n",
    "* Adriana Grande\n",
    "* The Offspring\n",
    "* Paramore\n",
    "* Nirvana\n",
    "\n",
    "### Data Collection\n",
    "I have collected all of the data using the Spotify API. The song list is hosted on Spotify and can be reached by following the link [here](https://open.spotify.com/playlist/2GsE0FXR8SZCYvRjjNn6t0?si=7c8ec7305fc34707). I have also used the Spotipy package which is a basic python wrapper for the Spotify API. The two main API calls for this project are get_audio_analysis and get_audio_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f160cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#base\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#spotipy\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "#sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dae68a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = SpotifyClientCredentials(client_id=os.environ['SPOTIFY_CLIENT_ID'],\n",
    "                                       client_secret= os.environ['SPOTIFY_CLIENT_SECRET'])\n",
    "sp = spotipy.Spotify(auth_manager=credentials, requests_timeout=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ab05c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_artist_list = ['Young Thug', 'Gunna', 'Lil Baby', 'J. Cole', 'Kendrick Lamar', 'Drake', \n",
    "                      'Tyler, The Creator', 'Justin Bieber', 'Billie Ellish', 'Taylor Swift',\n",
    "                      'Megan Thee Stallion', 'Adele', 'Olivia Rodrigo', 'Adriana Grande',\n",
    "                      'The Offspring', 'Paramore', 'Nirvana']\n",
    "playlist_url = 'https://open.spotify.com/playlist/2GsE0FXR8SZCYvRjjNn6t0?si=7c8ec7305fc34707'\n",
    "playlist = sp.playlist_items(playlist_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadcbb7f",
   "metadata": {},
   "source": [
    "### Reading Data\n",
    "In terms of data organization, I have split the data into 3 main parts depending on data granulariy\n",
    "\n",
    "#### General\n",
    "The general table is the least granular of the 3 at the song level. As such there are only about 100 rows. Since some of the songs have more than one artist on them, I have given each artist on the track their own row. This aspect is a little problematic since the most similar artists will be those who featured on the same track. I have made sure to prevent this issue by also accounting for song name in the analysis.\n",
    "\n",
    "#### Section\n",
    "The section table has more samples than the general tab with about 10 rows per song. This table along with the Segment table were the most difficult with multiple artists on one track. I was able to counter this by listening to the songs and taking account of when each artists would come on. The results of this are in the `song_urls.txt` file. There were a few categorical variables here including key, mode, and time signature that I vectorized using One Hot Encoding.\n",
    "\n",
    "#### Segment\n",
    "The segment table had the smallest granularity with about 1000 samples per song. This was the most important table for me since it also contained timbre. According to music theory, timbre is a good choice for distinguishing between how the music sounds. The Spotify API version is split into an array of 12 values. While the documentation does not reveal much about what these values mean individually, they were pivotal in the relational analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f037c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXTRACTING DATA FROM API CALLS\n",
    "\n",
    "gen_arr = []\n",
    "sect_arr = []\n",
    "segm_arr = []\n",
    "\n",
    "for sng in playlist['items']:\n",
    "    #dont go over rate limit!\n",
    "    #time.sleep(0.5)\n",
    "    base_dict = {}\n",
    "    sng = sng['track']\n",
    "    #get meta information: track name, artist/s\n",
    "    base_dict['artists'] = [artist_dict['name'] for artist_dict in sng['artists']]\n",
    "    base_dict['name'] = sng['name']\n",
    "    #get each track id to extract features\n",
    "    base_dict['id'] = sng['id']\n",
    "    #extract track information\n",
    "    sng_feats = sp.audio_features(base_dict['id'])[0]\n",
    "    sng_analy = sp.audio_analysis(base_dict['id'])\n",
    "    #add extracted info appropriately \n",
    "    sng_feats.update(base_dict)\n",
    "    gen_arr.append(sng_feats)\n",
    "    \n",
    "    sng['sections'] = sng_analy['sections']\n",
    "    [sect_dict.update(base_dict) for sect_dict in sng_analy['sections']]\n",
    "    sect_arr.append(sng_analy['sections'])\n",
    "    \n",
    "    sng['segments'] = sng_analy['segments']\n",
    "    [segm_dict.update(base_dict) for segm_dict in sng_analy['segments']]\n",
    "    segm_arr.append(sng_analy['segments'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3abefdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HELPER FUNCTIONS\n",
    "\n",
    "#splits the segment and sections tables into their own artists\n",
    "def fix_artists(row, time_df):\n",
    "    song_id = row.id\n",
    "    song_time_arr = time_df[time_df['id'] == song_id].values\n",
    "    start = row.start\n",
    "    if len(song_time_arr) > 0:\n",
    "        for correction in song_time_arr:\n",
    "            if start >= correction[1] and start < correction[2]:\n",
    "                row.artists = correction[3]\n",
    "        \n",
    "    else:\n",
    "        row.artists = row.artists[0]\n",
    "    return row\n",
    "\n",
    "#gets the 5 most similar artists to the row using jaccard similarity on the other rows \n",
    "def get_nearest_jacc(row, df):\n",
    "    #first get artist and song information\n",
    "    artist = row.artists\n",
    "    sng_id = row.id\n",
    "    #get samples from other artists that are not the same song, those would be too similar\n",
    "    non_sng_df = df[df['id'] != sng_id ]\n",
    "    non_sng_df = non_sng_df[non_sng_df['artists'] != artist]\n",
    "    #get jaccard and get 5 artists whose elements have the highest similarity\n",
    "    target_df = non_sng_df.drop(['id','artists'],axis=1)\n",
    "    target_idxs = target_df.multiply(row).sum(axis=1).divide(len(target_df.columns)).sort_values(ascending=False).index[0:5]\n",
    "    return df.loc[target_idxs,'artists'].values\n",
    "\n",
    "#gets the 5 most similar artists to the row using squared distance on the other rows \n",
    "def get_nearest(row, df):\n",
    "    #first get artist and song information\n",
    "    artist = row.artists\n",
    "    sng_id = row.id\n",
    "    #get samples from other artists that are not the same song, those would be too similar\n",
    "    non_sng_df = df[df['id'] != sng_id ]\n",
    "    non_sng_df = non_sng_df[non_sng_df['artists'] != artist]\n",
    "    #get distance between other elements and get 5 artists whose elements have the smallest distance\n",
    "    target_df = non_sng_df.drop(['id','artists'],axis=1)\n",
    "    target_idxs = target_df.subtract(row).pow(2).sum(axis=1).sort_values().index[0:5]\n",
    "    return df.loc[target_idxs, 'artists'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f43c458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#READING DATA AND FIXING FEATURED ARTISTS\n",
    "\n",
    "#turn features, sections, and segments to dataframes\n",
    "gen_df_raw = pd.DataFrame(gen_arr)\n",
    "sect_df_raw = pd.DataFrame(np.concatenate(sect_arr).tolist())\n",
    "segm_df_raw = pd.DataFrame(np.concatenate(segm_arr).tolist())\n",
    "#fix featuring artists\n",
    "gen_df = gen_df_raw.explode('artists').reset_index(drop=True)\n",
    "artist_time_df = pd.read_csv('song_urls.txt')\n",
    "sect_df = sect_df_raw.apply(fix_artists, axis=1, args=(artist_time_df,))\n",
    "segm_df = segm_df_raw.apply(fix_artists, axis=1, args=(artist_time_df,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f92a3f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENCODING PITCH AND TIMBRE ARRAYS FROM SEGMENT\n",
    "\n",
    "#split timbre and pitch arrays into their own columns\n",
    "pitches = ['C', 'C-sharp', 'D', 'D-sharp', 'E', 'F', 'F-sharp', 'G', 'G-sharp', 'A', 'B-flat', 'B']\n",
    "pitches_col = segm_df.pitches\n",
    "timbres = [\"timbre_{}\".format(x) for x in range(12)]\n",
    "timbre_col = segm_df.timbre\n",
    "\n",
    "for i in np.arange(12):\n",
    "    timbre_nm = \"timbre_{}\".format(i)\n",
    "    segm_df[pitches[i]] = pitches_col.apply(lambda x: x[i])\n",
    "    segm_df[timbre_nm] = timbre_col.apply(lambda y: y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "202c2f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONE HOT ENCODING PITCH, MODE, AND TIME SIGNATURE FROM CATEGORICAL VARIABLES FROM SECTION\n",
    "\n",
    "#One hot encode key (aka pitch), mode, and time signature categorical variables\n",
    "modes = ['minor', 'major']\n",
    "hotter = OneHotEncoder(sparse=False)\n",
    "\n",
    "#one hot encode\n",
    "key_trans = hotter.fit_transform(sect_df[['key']])\n",
    "mode_trans = hotter.fit_transform(sect_df[['mode']])\n",
    "time_trans = hotter.fit_transform(sect_df[['time_signature']])\n",
    "time_cats = ['time_sig_{}/4'.format(x) for x in hotter.categories_[0]]\n",
    "\n",
    "#transform to dataframe and add to main df\n",
    "pitches_hotted = pd.DataFrame(columns=pitches,data=key_trans)\n",
    "modes_hotted = pd.DataFrame(columns=modes, data=mode_trans)\n",
    "time_hotted = pd.DataFrame(columns=time_cats, data=time_trans)\n",
    "\n",
    "sect_df = pd.concat([sect_df, pitches_hotted, modes_hotted, time_hotted], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf9fe7b",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "In terms of feature selection I wanted to use features that were not present in other tables to minimize colinearity between each of the tables.I also wanted to select features that would be the most effective combined. For each set of numerical features, I made sure to keep all numbers between 0 and 1 since some of the variables had different ranges. For each table I choose the following features and similarity function\n",
    "\n",
    "* Segment - timbre - distance\n",
    "\n",
    "For segment I only chose timbre due to the massive amount of samples which needed to be managed. This section took the longest to compute at about 15 minutes due to the large number of expensive distance calculations. I choose minimum distance as the similarity function since the values were scaled from 0 to 1.\n",
    "\n",
    "* Section - key,mode,time_signature - Jaccard\n",
    "\n",
    "For section I choose to analyze the traditional musicality since there were fewer samples but still contained a decent amount of granularity. This table is probably the least valuable since it focuses on the music more than the artist. I used Jaccard similarity for this table since each of the variables were categorical.\n",
    "\n",
    "* General - danceability,energy,speechiness,acousticness,instrumentalness - distance\n",
    "\n",
    "For the general table since the granularity was at the song level, I wanted to leverage features that were more hollistic. The features are given directly from Spotify themselves so there is not much information on how exactly each of these features is derrived. I also used squared distance for this since all of the features were numerical.\n",
    "\n",
    "### Analysis\n",
    "In the analysis portion I found the 5 most similar segments, sections, or songs for each row that were not the same artist or the same song. After getting the 5 most similar segments, I got the artists for each of the 5 segments and moved on to the next row. At the end, I was able to group the rows by artist and I tallied up the artists in the 5 most similar arrays. I used this method instead of an average distance or some other summary statistic because I wanted to keep the level of analysis small. This was especially important to me for timbre in the segment table since each sample was inherently different  and I felt that there were enough samples to get a decent generalization from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32571437",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#DROPPING UNIMPORTANT COLUMNS IN SEGMENT\n",
    "\n",
    "segm_nonfeat_cols = ['start', 'duration', 'confidence', 'pitches', 'timbre','name']\n",
    "segm_clean_df = segm_df.drop(segm_nonfeat_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a88a05f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESCALING SEGMENT FEATURES TO MIN 0 AND MAX 1\n",
    "\n",
    "normer = MinMaxScaler()\n",
    "normed_segm = normer.fit_transform(segm_clean_df.drop(['id', 'artists'], axis=1))\n",
    "segm_scaled_df = pd.DataFrame(columns=normer.feature_names_in_, data=normed_segm)\n",
    "segm_scaled_df = pd.concat([segm_scaled_df, segm_clean_df[['id', 'artists']]],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b70d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIND MOST SIMILAR IN SEGMENT USING SQUARED DISTANCE\n",
    "#WARNING: THIS SECTION TAKES A WHILE TO RUN\n",
    "\n",
    "normed_timbre = normer.fit_transform(segm_clean_df.loc[:,timbres])\n",
    "timbre_scaled_df = pd.DataFrame(columns=normer.feature_names_in_, data=normed_timbre)\n",
    "timbre_scaled_df = pd.concat([timbre_scaled_df, segm_clean_df[['id','artists']]])\n",
    "\n",
    "most_sim_timbre = timbre_scaled_df.apply(get_nearest, args=(timbre_scaled_df,),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b024d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "segm_results = most_sim_timbre.explode().reset_index(drop=True).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4d8f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "segm_results.plot(kind='bar', title='Similarity to Young Thug (Section)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e20c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROPPING UNIMORTANT COLUMNS IN SECTION\n",
    "sect_nonfeat_cols = ['start','duration','confidence','tempo_confidence','key', 'key_confidence',\n",
    "                     'mode', 'mode_confidence', 'time_signature', 'time_signature_confidence',\n",
    "                     'name', 'loudness', 'tempo']\n",
    "sect_clean_df = sect_df.drop(sect_nonfeat_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a17e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIND MOST SIMILAR IN SECTION USING JACCARD SIM\n",
    "\n",
    "sect_results = sect_clean_df[sect_clean_df['artists']=='Young Thug'].apply(get_nearest_jacc, args=(sect_clean_df,),axis=1).explode().value_counts()\n",
    "sect_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a839acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sect_results.plot(kind='bar', title='Similarity to Young Thug (Section)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3c27bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROPPING UNIMPORTANT COLUMNS IN GENERAL\n",
    "\n",
    "gen_nonfeat_cols = ['key', 'mode','type', 'uri', 'track_href', 'analysis_url', 'duration_ms', \n",
    "                    'time_signature', 'name']\n",
    "gen_clean_df = gen_df.drop(gen_nonfeat_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53ef80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESCALING GENERAL FEATURES TO MIN 0 AND MAX 1\n",
    "\n",
    "normer = MinMaxScaler()\n",
    "normed_gen = normer.fit_transform(gen_clean_df.drop(['id', 'artists'], axis=1))\n",
    "gen_scaled_df = pd.DataFrame(columns=normer.feature_names_in_, data=normed_gen)\n",
    "gen_scaled_df = pd.concat([gen_scaled_df, gen_clean_df[['id', 'artists']]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb27035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIND MOST SIMILAR IN GENERAL USING SQUARED DISTANCE\n",
    "gen_target_df = gen_scaled_df.loc[:,['artists','id','danceability', 'energy', 'speechiness','acousticness', 'instrumentalness']]\n",
    "gen_results_df = pd.concat([gen_scaled_df, gen_target_df.apply(get_nearest, args=(gen_scaled_df,),axis=1)],axis=1)\n",
    "\n",
    "gen_results = gen_results_df.explode(0).groupby('artists').apply(lambda x: x[0].value_counts())['Young Thug']\n",
    "gen_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c008332",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_results.plot(kind='bar', title='Similarity to Young Thug (General)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ceab22",
   "metadata": {},
   "source": [
    "### Results\n",
    "Overall I was excited to see different results for each of the tables I looked at. \n",
    "\n",
    "Starting with the results from the General table, these were the results I would expect when asking someone who Young Thug sounds most like. Young Thug works closely with both Gunna and Drake. Lil Baby is also expected here as he is also considered another 'mumble rapper'. One surprise is that Ariana Grande was able to outrank Kendrick Lamar even if it was just by a single mention.\n",
    "\n",
    "The results from section were the most surprising for me. The biggest surprise is that the top 2 artists are alternative and pop artists respectively (Travis Scott isn't officially being analyzed but he did feature in several songs). Furthurmore, another surpirse is seeing Adele tied with Gunna in mentions. These results reveal that there is more to the sound of music than the chords and time signatures which is where timbre comes in.\n",
    "\n",
    "The results from segment were the most anticipated out of the 3 tables. One big surprise off the bat is seeing J. Cole beating out both Drake and Gunna for the top spot. These results make sense based on the songs I sampled from each artist. For example, for J. Cole I sampled songs where he was more lyrically involved as well as Young Thug. Where I suspect J. Cole took the cake was with Young Thug's sample of **Feel It** and J. Cole's **Foldin Clothes**. These two songs are both very soft and melodic songs on a roster of songs that tend to be more energetic and intense. Another piece of analysis I noticed was that Billie Elish tended to be at the bottom of most of these comparisons. While it seems that J. Cole, Drake, and Gunna are the most similar to Young Thug, Billie Elish seems to be the most disimilar.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
